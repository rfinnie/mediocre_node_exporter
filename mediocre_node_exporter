#!/usr/bin/env python

# mediocre_node_exporter - A minimal node_exporter reimplementation
# Copyright (C) 2017 Ryan Finnie
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301, USA.

import sys
import os
import BaseHTTPServer
import socket
import cStringIO
import gzip
import time
import platform
import re


INDEX_PAGE_CONTENT = """<html>
<head><title>Mediocre Node Exporter</title></head>
<body>
<h1>Mediocre Node Exporter</h1>
<p><a href="{telemetry_path}">Metrics</a></p>
</body>
</html>"""

NOTFOUND_PAGE_CONTENT = """<html>
<head><title>404 Not Found</title></head>
<body>
<h1>Not Found</h1>
<p>The requested URL was not found on this server.</p>
</body>
</html>"""


def entry(values, type='gauge', help=None):
    out = {
        'values': values,
        'type': type,
        'help': help,
    }
    return(out)


def update_dict(source, to_merge):
    for (k, v) in to_merge.items():
        source[k] = v


class Collectors():
    def __init__(self, config):
        self.config = config
        self.collectors_available = {
            'conntrack': (self.conntrack,),
            'diskstats': (self.diskstats,),
            'entropy': (self.entropy,),
            'filefd': (self.filefd,),
            'filesystem': (self.filesystem,),
            'loadavg': (self.loadavg,),
            'meminfo': (self.meminfo,),
            'netdev': (self.netdev,),
            'stat': (self.stat,),
            'time': (self.time,),
            'uname': (self.uname,),
            'vmstat': (self.vmstat,),
        }

    def run_collector(self, collector_name, collector_metrics, times, successes):
        start_time = time.time()
        try:
            collector_output = self.collectors_available[collector_name][0]()
        except:
            end_time = time.time()
            times.append(({'collector': collector_name}, (end_time - start_time)))
            successes.append(({'collector': collector_name}, 0))
            return
        end_time = time.time()
        update_dict(collector_metrics, collector_output)
        times.append(({'collector': collector_name}, (end_time - start_time)))
        successes.append(({'collector': collector_name}, 1))

    def assemble_stats(self):
        times = []
        successes = []
        out = {}
        output = ''
        for collector_name in self.collectors_available:
            self.run_collector(collector_name, out, times, successes)

        out['node_scrape_collector_duration_seconds'] = entry(
            times,
            'gauge',
            'node_exporter: Duration of a collector scrape.',
        )
        out['node_scrape_collector_success'] = entry(
            successes,
            'gauge',
            'node_exporter: Whether a collector succeeded.',
        )

        for k in sorted(out):
            if out[k]['help']:
                output += '# HELP %s %s\n' % (k, out[k]['help'])
            output += '# TYPE %s %s\n' % (k, out[k]['type'])
            for a in out[k]['values']:
                if a[0]:
                    output += '%s{%s} %s\n' % (
                        k,
                        ','.join(
                            ['%s="%s"' % (x, a[0][x]) for x in sorted(a[0].keys())]
                        ),
                        a[1]
                    )
                else:
                    output += '%s %s\n' % (k, a[1])

        if self.config.textfile_directory:
            output += read_textfiles(config.textfile_directory)

        return(output)

    def filesystem(self):
        out = {}
        values_available = []
        values_files = []
        values_files_free = []
        values_free = []
        values_readonly = []
        values_size = []
        mounts = []
        with open('/proc/mounts') as f:
            for l in f:
                mounts.append(l.rstrip().split(' '))
        for l in mounts:
            mount = l[1]
            vfs = os.statvfs(mount)
            labels = {
                'device': l[0],
                'fstype': l[2],
                'mountpoint': mount,
            }
            if l[3].startswith('ro'):
                readonly = 1
            else:
                readonly = 0

            values_available.append((labels, vfs.f_bavail * vfs.f_bsize))
            values_files.append((labels, vfs.f_files))
            values_files_free.append((labels, vfs.f_ffree))
            values_free.append((labels, vfs.f_bfree * vfs.f_bsize))
            values_readonly.append((labels, readonly))
            values_size.append((labels, vfs.f_blocks * vfs.f_bsize))
        out['node_filesystem_avail'] = entry(
            values_available,
            'gauge',
            'Filesystem space available to non-root users in bytes.',
        )
        out['node_filesystem_files'] = entry(
            values_files,
            'gauge',
            'Filesystem total file nodes.',
        )
        out['node_filesystem_files_free'] = entry(
            values_files_free,
            'gauge',
            'Filesystem total free file nodes.',
        )
        out['node_filesystem_free'] = entry(
            values_free,
            'gauge',
            'Filesystem free space in bytes.',
        )
        out['node_filesystem_readonly'] = entry(
            values_readonly,
            'gauge',
            'Filesystem read-only status.',
        )
        out['node_filesystem_size'] = entry(
            values_size,
            'gauge',
            'Filesystem size in bytes.',
        )
        return(out)

    def diskstats(self):
        out = {}
        metrics_info = [
            ('node_disk_reads_completed', 'counter', 'The total number of reads completed successfully.'),
            ('node_disk_reads_merged', 'counter', 'The total number of reads merged. See https://www.kernel.org/doc/Documentation/iostats.txt.'),
            ('node_disk_sectors_read', 'counter', 'The total number of sectors read successfully.'),
            ('node_disk_read_time_ms', 'counter', 'The total number of milliseconds spent by all reads.'),
            ('node_disk_writes_completed', 'counter', 'The total number of writes completed successfully.'),
            ('node_disk_writes_merged', 'counter', 'The number of writes merged. See https://www.kernel.org/doc/Documentation/iostats.txt.'),
            ('node_disk_sectors_written', 'counter', 'The total number of sectors written successfully.'),
            ('node_disk_write_time_ms', 'counter', 'This is the total number of milliseconds spent by all writes.'),
            ('node_disk_io_now', 'counter', 'The number of I/Os currently in progress.'),
            ('node_disk_io_time_ms', 'counter', 'Total Milliseconds spent doing I/Os.'),
            ('node_disk_io_time_weighted', 'counter', 'The weighted # of milliseconds spent doing I/Os. See https://www.kernel.org/doc/Documentation/iostats.txt.'),
            ('node_disk_bytes_read', 'counter', 'The total number of bytes read successfully.'),
            ('node_disk_bytes_written', 'counter', 'The total number of bytes written successfully.'),
        ]
        values = {}
        for (metric, metric_type, metric_help) in metrics_info:
            values[metric] = []
        diskstats = []
        with open('/proc/diskstats') as f:
            for l in f:
                diskstats.append(re.split('\s+', l.strip()))
        for l in diskstats:
            labels = {
                'device': l[2],
            }
            values['node_disk_reads_completed'].append((labels, int(l[3])))
            values['node_disk_reads_merged'].append((labels, int(l[4])))
            values['node_disk_sectors_read'].append((labels, int(l[5])))
            values['node_disk_read_time_ms'].append((labels, int(l[6])))
            values['node_disk_writes_completed'].append((labels, int(l[7])))
            values['node_disk_writes_merged'].append((labels, int(l[8])))
            values['node_disk_sectors_written'].append((labels, int(l[9])))
            values['node_disk_write_time_ms'].append((labels, int(l[10])))
            values['node_disk_io_now'].append((labels, int(l[11])))
            values['node_disk_io_time_ms'].append((labels, int(l[12])))
            values['node_disk_io_time_weighted'].append((labels, int(l[13])))
            values['node_disk_bytes_read'].append((labels, (int(l[5]) * 512)))
            values['node_disk_bytes_written'].append((labels, (int(l[9]) * 512)))

        for (metric, metric_type, metric_help) in metrics_info:
            out[metric] = entry(values[metric], metric_type, metric_help)
        return out

    def stat(self):
        out = {}
        statdata = {}
        with open('/proc/stat') as f:
            for l in f:
                llist = l.rstrip().split(' ')
                k = llist.pop(0)
                statdata[k] = llist

        cpu_modes = ['user', 'nice', 'system', 'idle', 'iowait', 'irq', 'softirq', 'steal', 'guest', 'guest_nice']
        cpu_values = []
        for st in statdata:
            if not st.startswith('cpu'):
                continue
            if st == 'cpu':
                continue
            for i in range(len(cpu_modes)):
                try:
                    cpu_values.append(({'cpu': st, 'mode': cpu_modes[i]}, int(statdata[st][i])))
                except IndexError:
                    continue
        out['node_cpu'] = entry(
            cpu_values,
            'counter',
            'Seconds the cpus spent in each mode.',
        )
        out['node_boot_time'] = entry(
            [({}, int(statdata['btime'][0]))],
            'gauge',
            'Node boot time, in unixtime.',
        )
        out['node_intr'] = entry(
            [({}, int(statdata['intr'][0]))],
            'counter',
            'Total number of interrupts serviced.',
        )
        out['node_context_switches'] = entry(
            [({}, int(statdata['ctxt'][0]))],
            'counter',
            'Total number of context switches.',
        )
        out['node_forks'] = entry(
            [({}, int(statdata['processes'][0]))],
            'counter',
            'Total number of forks.',
        )
        out['node_procs_blocked'] = entry(
            [({}, int(statdata['procs_blocked'][0]))],
            'gauge',
            'Number of processes blocked waiting for I/O to complete.',
        )
        out['node_procs_running'] = entry(
            [({}, int(statdata['procs_running'][0]))],
            'gauge',
            'Number of processes in runnable state.',
        )
        return(out)

    def loadavg(self):
        out = {}
        loadavg = os.getloadavg()
        out['node_load1'] = entry(
            [({}, loadavg[0])],
            'gauge',
            '1m load average.',
        )
        out['node_load5'] = entry(
            [({}, loadavg[1])],
            'gauge',
            '5m load average.',
        )
        out['node_load15'] = entry(
            [({}, loadavg[2])],
            'gauge',
            '15m load average.',
        )
        return(out)

    def meminfo(self):
        out = {}
        lines = []
        with open('/proc/meminfo') as f:
            for l in f:
                lines.append(re.split('\s+', l.strip()))
        for l in lines:
            if len(l) == 2:
                v = int(l[1])
            elif len(l) == 3:
                if l[2] == 'kB':
                    v = int(l[1]) * 1024
                else:
                    continue
            else:
                continue
            k = l[0].replace(':', '').replace('(', '_').replace(')', '')
            out['node_memory_%s' % k] = entry(
                [({}, v)],
                'gauge',
                'Memory information field %s.' % k,
            )
        return(out)

    def vmstat(self):
        out = {}
        lines = []
        with open('/proc/vmstat') as f:
            for l in f:
                lines.append(l.rstrip().split(' '))
        for l in lines:
            k = l[0]
            v = int(l[1])
            out['node_vmstat_%s' % k] = entry(
                [({}, v)],
                'untyped',
                '/proc/vmstat information field %s.' % k,
            )
        return(out)

    def netdev(self):
        out = {}
        interfaces = os.listdir('/sys/class/net')
        statmap = {
            'receive_bytes': 'rx_bytes',
            'receive_compressed': 'rx_compressed',
            'receive_drop': 'rx_dropped',
            'receive_errs': 'rx_errors',
            'receive_fifo': 'rx_fifo_errors',
            'receive_frame': 'rx_frame_errors',
            'receive_multicast': 'multicast',
            'receive_packets': 'rx_packets',
            'transmit_bytes': 'tx_bytes',
            'transmit_compressed': 'tx_compressed',
            'transmit_drop': 'tx_dropped',
            'transmit_errs': 'tx_errors',
            'transmit_fifo': 'tx_fifo_errors',
            'transmit_frame': 'tx_frame_errors',
            'transmit_multicast': None,
            'transmit_packets': 'tx_packets',
        }

        for statkey in sorted(statmap):
            values = []
            for iface in interfaces:
                labels = {
                    'device': iface,
                }
                if not statmap[statkey]:
                    val = 0
                elif not os.path.exists('/sys/class/net/%s/statistics/%s' % (iface, statmap[statkey])):
                    val = 0
                else:
                    with open('/sys/class/net/%s/statistics/%s' % (iface, statmap[statkey])) as f:
                        val = int(f.read().rstrip())
                values.append((labels, val))
            out['node_network_%s' % statkey] = entry(
                values,
                'gauge',
                'Network device statistic %s.' % statkey,
            )
        return(out)

    def conntrack(self):
        out = {}
        if os.path.exists('/proc/sys/net/netfilter/nf_conntrack_count'):
            with open('/proc/sys/net/netfilter/nf_conntrack_count') as f:
                out['node_nf_conntrack_entries'] = entry(
                    [({}, int(f.read().rstrip()))],
                    'gauge',
                    'Number of currently allocated flow entries for connection tracking.',
                )
        if os.path.exists('/proc/sys/net/netfilter/nf_conntrack_max'):
            with open('/proc/sys/net/netfilter/nf_conntrack_max') as f:
                out['node_nf_conntrack_entries_limit'] = entry(
                    [({}, int(f.read().rstrip()))],
                    'gauge',
                    'Maximum size of connection tracking table.',
                )
        return(out)

    def time(self):
        out = {}
        out['node_time'] = entry(
            [({}, int(time.time()))],
            'gauge',
            'System time in seconds since epoch (1970).',
        )
        return(out)

    def entropy(self):
        out = {}
        if os.path.exists('/proc/sys/kernel/random/entropy_avail'):
            with open('/proc/sys/kernel/random/entropy_avail') as f:
                out['node_entropy_available_bits'] = entry(
                    [({}, int(f.read().rstrip()))],
                    'gauge',
                    'Bits of available entropy.',
                )
        return(out)

    def filefd(self):
        out = {}
        if os.path.exists('/proc/sys/fs/file-nr'):
            with open('/proc/sys/fs/file-nr') as f:
                fdlist = f.read().rstrip().split('\t')
            out['node_filefd_allocated'] = entry(
                [({}, int(fdlist[0]))],
                'gauge',
                'File descriptor statistics: allocated.',
            )
            out['node_filefd_maximum'] = entry(
                [({}, int(fdlist[2]))],
                'gauge',
                'File descriptor statistics: maximum.',
            )
        return(out)

    def uname(self):
        out = {}
        uname = platform.uname()
        labels = {
            'sysname': uname[0],
            'nodename': uname[1],
            'release': uname[2],
            'version': uname[3],
            'machine': uname[4],
            'domainname': '(none)',
        }
        out['node_uname_info'] = entry(
            [(labels, 1)],
            'gauge',
            'Labeled system information as provided by the uname system call.',
        )
        return(out)


def read_textfiles(path):
    out = ''
    try:
        promfiles = [fn for fn in os.listdir(path) if os.path.isfile(os.path.join(path, fn)) and fn.endswith('.prom')]
    except (IOError, OSError):
        return out
    for fn in sorted(promfiles):
        try:
            with open(os.path.join(path, fn)) as f:
                out += f.read()
        except (IOError, OSError):
            continue
    return out


def parse_args():
    import argparse

    parser = argparse.ArgumentParser(
        description='mediocre_node_exporter',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        '-collector.textfile.directory', type=str, default=None,
        dest='textfile_directory',
        help='directory to read text files with metrics from',
    )
    parser.add_argument(
        '-web.listen-address', type=str, default=':9100',
        dest='listen_address',
        help='address on which to expose metrics and web interface',
    )
    parser.add_argument(
        '-web.telemetry-path', type=str, default='/metrics',
        dest='telemetry_path',
        help='path under which to expose metrics',
    )
    parser.add_argument(
        '-dump', action='store_true',
        help='do not start web server, just dump stats',
    )
    return parser.parse_args()


class HTTPServerV6(BaseHTTPServer.HTTPServer):
    address_family = socket.AF_INET6


class NodeExporterHandler(BaseHTTPServer.BaseHTTPRequestHandler):
    config = None

    def do_GET(self):
        if self.path == self.config.telemetry_path:
            content = {
                'code': 200,
                'output': self.collectors.assemble_stats(),
                'content_type': 'text/plain; version=0.0.4',
            }
        elif self.path == '/':
            content = {
                'code': 200,
                'output': INDEX_PAGE_CONTENT.format(
                    telemetry_path=self.config.telemetry_path,
                ),
                'content_type': 'text/html; charset=utf-8',
            }
        else:
            content = {
                'code': 404,
                'output': NOTFOUND_PAGE_CONTENT,
                'content_type': 'text/html; charset=utf-8',
            }

        self.protocol_version = self.request_version
        self.send_response(content['code'])
        self.send_header('Content-Type', content['content_type'])
        output = content['output']
        if self.headers.getheader('Accept-Encoding') and ('gzip' in self.headers.getheader('Accept-Encoding')):
            zbuf = cStringIO.StringIO()
            zfile = gzip.GzipFile(mode='wb', compresslevel=6, fileobj=zbuf)
            zfile.write(output)
            zfile.close()
            output = zbuf.getvalue()
            self.send_header('Content-Encoding', 'gzip')
        self.send_header('Content-Length', str(len(output)))
        self.end_headers()
        self.wfile.write(output)
        self.wfile.close()


if __name__ == '__main__':
    config = parse_args()
    if config.dump:
        sys.stdout.write(Collectors(config).assemble_stats())
        sys.exit(0)
    server_port = int(config.listen_address.split(':')[-1])
    server_host = ':'.join(config.listen_address.split(':')[:-1])
    if server_host == '':
        test_addrinfo = socket.getaddrinfo(None, server_port)[0]
        if test_addrinfo[0] == socket.AF_INET6:
            server_host = '::'
        else:
            server_host = '0.0.0.0'
    if (server_host[0] == '[') and (server_host[-1] == ']'):
        server_host = server_host[1:-1]
    server_addrinfo = socket.getaddrinfo(server_host, server_port)[0]
    if server_addrinfo[0] == socket.AF_INET6:
        server_class = HTTPServerV6
    else:
        server_class = BaseHTTPServer.HTTPServer
    httpd = server_class(
        (server_addrinfo[-1][0], server_addrinfo[-1][1]),
        NodeExporterHandler
    )
    httpd.RequestHandlerClass.config = config
    httpd.RequestHandlerClass.collectors = Collectors(config)
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        pass
    httpd.server_close()
